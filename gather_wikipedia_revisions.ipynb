{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# requirements\n",
    "+ mwparserfromhell (0.6.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The nb_black extension is already loaded. To reload it, use:\n",
      "  %reload_ext nb_black\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 55;\n",
       "                var nbb_unformatted_code = \"# format cells using black\\n%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"# format cells using black\\n%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# format cells using black\n",
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import pandas as pd\\nimport pickle\\nimport os\\nimport re\\nimport requests\\nimport mwparserfromhell\\n\\nfrom time import sleep\\n\\npd.options.display.max_columns = 20\\npd.options.display.max_rows = 50\\npd.options.mode.chained_assignment = None\";\n",
       "                var nbb_formatted_code = \"import pandas as pd\\nimport pickle\\nimport os\\nimport re\\nimport requests\\nimport mwparserfromhell\\n\\nfrom time import sleep\\n\\npd.options.display.max_columns = 20\\npd.options.display.max_rows = 50\\npd.options.mode.chained_assignment = None\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import mwparserfromhell\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "pd.options.display.max_columns = 20\n",
    "pd.options.display.max_rows = 50\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"api_url = \\\"https://de.wikipedia.org/w/api.php\\\"\\n# parameters\\nparams = {\\n    \\\"action\\\": \\\"query\\\",\\n    \\\"titles\\\": \\\"Albert Einstein\\\",\\n    \\\"prop\\\": \\\"revisions\\\",\\n    \\\"rvprop\\\": \\\"ids|timestamp|comment|content|flags|user|userid\\\",\\n    \\\"rvlimit\\\": \\\"max\\\",\\n    \\\"continue\\\": \\\"\\\",\\n    \\\"format\\\": \\\"json\\\",\\n}\\nparams[\\\"titles\\\"] = params[\\\"titles\\\"].replace(\\\" \\\", \\\"_\\\")\";\n",
       "                var nbb_formatted_code = \"api_url = \\\"https://de.wikipedia.org/w/api.php\\\"\\n# parameters\\nparams = {\\n    \\\"action\\\": \\\"query\\\",\\n    \\\"titles\\\": \\\"Albert Einstein\\\",\\n    \\\"prop\\\": \\\"revisions\\\",\\n    \\\"rvprop\\\": \\\"ids|timestamp|comment|content|flags|user|userid\\\",\\n    \\\"rvlimit\\\": \\\"max\\\",\\n    \\\"continue\\\": \\\"\\\",\\n    \\\"format\\\": \\\"json\\\",\\n}\\nparams[\\\"titles\\\"] = params[\\\"titles\\\"].replace(\\\" \\\", \\\"_\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "api_url = \"https://de.wikipedia.org/w/api.php\"\n",
    "# parameters\n",
    "params = {\n",
    "    \"action\": \"query\",\n",
    "    \"titles\": \"Albert Einstein\",\n",
    "    \"prop\": \"revisions\",\n",
    "    \"rvprop\": \"ids|timestamp|comment|content|flags|user|userid\",\n",
    "    \"rvlimit\": \"max\",\n",
    "    \"continue\": \"\",\n",
    "    \"format\": \"json\",\n",
    "}\n",
    "params[\"titles\"] = params[\"titles\"].replace(\" \", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 54;\n",
       "                var nbb_unformatted_code = \"def get_revisions(request_params):\\n    pageids = request_params.get(\\\"pageids\\\")\\n    titles = request_params.get(\\\"titles\\\")\\n    if pageids:\\n        pageids = str(pageids).split(\\\"|\\\")\\n        if len(pageids) > 1:\\n            raise Exception(\\\"Please provide only 1 page id in request_params.\\\")\\n        page_id = pageids[0]\\n    elif titles:\\n        titles = str(titles).split(\\\"|\\\")\\n        if len(titles) > 1:\\n            raise Exception(\\\"Please provide only 1 page title in request_params.\\\")\\n        page_title = titles[0]\\n    else:\\n        raise Exception(\\n            'Please provide \\\"pageids\\\" or \\\"titles\\\" parameter in request_params.'\\n        )\\n    rvcontinue = request_params.get(\\\"rvcontinue\\\")\\n    session = requests.session()\\n    # headers = {'User-Agent': ,\\n    #            'From': }\\n    while True:\\n        # continue downloading as long as we reach the given rev_id limit\\n        if rvcontinue is not None:\\n            request_params[\\\"rvcontinue\\\"] = rvcontinue\\n        result = session.get(url=api_url, params=request_params, timeout=30).json()\\n        if \\\"error\\\" in result:\\n            raise Exception(\\n                \\\"Wikipedia API returned the following error:\\\" + str(result[\\\"error\\\"])\\n            )\\n        # if 'query' in result:\\n        pages = result[\\\"query\\\"][\\\"pages\\\"]\\n        if \\\"-1\\\" in pages:\\n            raise Exception(\\n                \\\"The article ({}) you are trying to request does not exist!\\\".format(\\n                    page_title or page_id\\n                )\\n            )\\n        _, page = result[\\\"query\\\"][\\\"pages\\\"].popitem()\\n        for rev_data in page.get(\\\"revisions\\\", []):\\n            yield rev_data\\n        if \\\"continue\\\" not in result:\\n            break\\n        rvcontinue = result[\\\"continue\\\"][\\\"rvcontinue\\\"]\\n        # sleep(0.005)\\n        sleep(0.01)\";\n",
       "                var nbb_formatted_code = \"def get_revisions(request_params):\\n    pageids = request_params.get(\\\"pageids\\\")\\n    titles = request_params.get(\\\"titles\\\")\\n    if pageids:\\n        pageids = str(pageids).split(\\\"|\\\")\\n        if len(pageids) > 1:\\n            raise Exception(\\\"Please provide only 1 page id in request_params.\\\")\\n        page_id = pageids[0]\\n    elif titles:\\n        titles = str(titles).split(\\\"|\\\")\\n        if len(titles) > 1:\\n            raise Exception(\\\"Please provide only 1 page title in request_params.\\\")\\n        page_title = titles[0]\\n    else:\\n        raise Exception(\\n            'Please provide \\\"pageids\\\" or \\\"titles\\\" parameter in request_params.'\\n        )\\n    rvcontinue = request_params.get(\\\"rvcontinue\\\")\\n    session = requests.session()\\n    # headers = {'User-Agent': ,\\n    #            'From': }\\n    while True:\\n        # continue downloading as long as we reach the given rev_id limit\\n        if rvcontinue is not None:\\n            request_params[\\\"rvcontinue\\\"] = rvcontinue\\n        result = session.get(url=api_url, params=request_params, timeout=30).json()\\n        if \\\"error\\\" in result:\\n            raise Exception(\\n                \\\"Wikipedia API returned the following error:\\\" + str(result[\\\"error\\\"])\\n            )\\n        # if 'query' in result:\\n        pages = result[\\\"query\\\"][\\\"pages\\\"]\\n        if \\\"-1\\\" in pages:\\n            raise Exception(\\n                \\\"The article ({}) you are trying to request does not exist!\\\".format(\\n                    page_title or page_id\\n                )\\n            )\\n        _, page = result[\\\"query\\\"][\\\"pages\\\"].popitem()\\n        for rev_data in page.get(\\\"revisions\\\", []):\\n            yield rev_data\\n        if \\\"continue\\\" not in result:\\n            break\\n        rvcontinue = result[\\\"continue\\\"][\\\"rvcontinue\\\"]\\n        # sleep(0.005)\\n        sleep(0.01)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_revisions(request_params):\n",
    "    pageids = request_params.get(\"pageids\")\n",
    "    titles = request_params.get(\"titles\")\n",
    "    if pageids:\n",
    "        pageids = str(pageids).split(\"|\")\n",
    "        if len(pageids) > 1:\n",
    "            raise Exception(\"Please provide only 1 page id in request_params.\")\n",
    "        page_id = pageids[0]\n",
    "    elif titles:\n",
    "        titles = str(titles).split(\"|\")\n",
    "        if len(titles) > 1:\n",
    "            raise Exception(\"Please provide only 1 page title in request_params.\")\n",
    "        page_title = titles[0]\n",
    "    else:\n",
    "        raise Exception(\n",
    "            'Please provide \"pageids\" or \"titles\" parameter in request_params.'\n",
    "        )\n",
    "    rvcontinue = request_params.get(\"rvcontinue\")\n",
    "    session = requests.session()\n",
    "    # headers = {'User-Agent': ,\n",
    "    #            'From': }\n",
    "    while True:\n",
    "        # continue downloading as long as we reach the given rev_id limit\n",
    "        if rvcontinue is not None:\n",
    "            request_params[\"rvcontinue\"] = rvcontinue\n",
    "        result = session.get(url=api_url, params=request_params, timeout=30).json()\n",
    "        if \"error\" in result:\n",
    "            raise Exception(\n",
    "                \"Wikipedia API returned the following error:\" + str(result[\"error\"])\n",
    "            )\n",
    "        # if 'query' in result:\n",
    "        pages = result[\"query\"][\"pages\"]\n",
    "        if \"-1\" in pages:\n",
    "            raise Exception(\n",
    "                \"The article ({}) you are trying to request does not exist!\".format(\n",
    "                    page_title or page_id\n",
    "                )\n",
    "            )\n",
    "        _, page = result[\"query\"][\"pages\"].popitem()\n",
    "        for rev_data in page.get(\"revisions\", []):\n",
    "            yield rev_data\n",
    "        if \"continue\" not in result:\n",
    "            break\n",
    "        rvcontinue = result[\"continue\"][\"rvcontinue\"]\n",
    "        # sleep(0.005)\n",
    "        sleep(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load wikipedia article titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20484\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"path = os.path.abspath(\\\"\\\")\\ndata_df_rel = \\\"data/df/\\\"\\ndata_df_ndb_abs = os.path.join(path, data_df_rel, \\\"df_ndb_wikipedia.pkl\\\")\\ncorpus = pd.read_pickle(data_df_ndb_abs)\\ntitles = corpus[\\\"wikipedia_title\\\"].tolist()\\ngnds = corpus[\\\"gnd\\\"].tolist()\\nassert len(titles) == len(gnds)\\nnumber_biographies = len(gnds)\\nprint(len(gnds))\";\n",
       "                var nbb_formatted_code = \"path = os.path.abspath(\\\"\\\")\\ndata_df_rel = \\\"data/df/\\\"\\ndata_df_ndb_abs = os.path.join(path, data_df_rel, \\\"df_ndb_wikipedia.pkl\\\")\\ncorpus = pd.read_pickle(data_df_ndb_abs)\\ntitles = corpus[\\\"wikipedia_title\\\"].tolist()\\ngnds = corpus[\\\"gnd\\\"].tolist()\\nassert len(titles) == len(gnds)\\nnumber_biographies = len(gnds)\\nprint(len(gnds))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = os.path.abspath(\"\")\n",
    "data_df_rel = \"data/df/\"\n",
    "data_df_ndb_abs = os.path.join(path, data_df_rel, \"df_ndb_wikipedia.pkl\")\n",
    "corpus = pd.read_pickle(data_df_ndb_abs)\n",
    "titles = corpus[\"wikipedia_title\"].tolist()\n",
    "gnds = corpus[\"gnd\"].tolist()\n",
    "assert len(titles) == len(gnds)\n",
    "number_biographies = len(gnds)\n",
    "print(len(gnds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## store additional data for each article\n",
    "+ number of revisions within each month\n",
    "+ creator and other contributors of each article "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"def get_months() -> dict:\\n    min_month = 6\\n    min_year = 2001\\n    max_month = 5\\n    max_year = 2022\\n    months = {}\\n    for year in range(min_year, max_year + 1):\\n        for month in range(1, 13):\\n            padding_zero = \\\"\\\"\\n            if year == min_year and month < min_month:\\n                continue\\n            if year == max_year and month > max_month:\\n                continue\\n            if month < 10:\\n                padding_zero = \\\"0\\\"\\n            months[\\n                f\\\"{year}-{padding_zero}{month}\\\"\\n            ] = 0  # number of revisions for that article in that month\\n    return months\";\n",
       "                var nbb_formatted_code = \"def get_months() -> dict:\\n    min_month = 6\\n    min_year = 2001\\n    max_month = 5\\n    max_year = 2022\\n    months = {}\\n    for year in range(min_year, max_year + 1):\\n        for month in range(1, 13):\\n            padding_zero = \\\"\\\"\\n            if year == min_year and month < min_month:\\n                continue\\n            if year == max_year and month > max_month:\\n                continue\\n            if month < 10:\\n                padding_zero = \\\"0\\\"\\n            months[\\n                f\\\"{year}-{padding_zero}{month}\\\"\\n            ] = 0  # number of revisions for that article in that month\\n    return months\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_months() -> dict:\n",
    "    min_month = 6\n",
    "    min_year = 2001\n",
    "    max_month = 5\n",
    "    max_year = 2022\n",
    "    months = {}\n",
    "    for year in range(min_year, max_year + 1):\n",
    "        for month in range(1, 13):\n",
    "            padding_zero = \"\"\n",
    "            if year == min_year and month < min_month:\n",
    "                continue\n",
    "            if year == max_year and month > max_month:\n",
    "                continue\n",
    "            if month < 10:\n",
    "                padding_zero = \"0\"\n",
    "            months[\n",
    "                f\"{year}-{padding_zero}{month}\"\n",
    "            ] = 0  # number of revisions for that article in that month\n",
    "    return months"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get and store revisions (monthly newest revision) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed biographies: 20483/20484 (pkl stored: 0)| skipped: 27\n",
      "\n",
      "parser_errors=0\n",
      "connection_errors=0\n",
      "missing_first_revision=22\n",
      "missing_userid_key=5\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 56;\n",
       "                var nbb_unformatted_code = \"path = os.path.abspath(\\\"\\\")\\ndata_revisions_rel = \\\"data/revisions/\\\"\\ndata_revisions_meta_rel = \\\"data/revisions_meta/\\\"\\nj = 0\\nk = 0  # biographies with revsions\\nparser_errors = 0\\nconnection_errors = 0\\nmissing_revision = {}\\nmissing_userid_key = 0\\nmissing_first_revision = 0  # parentid != 0 (first revision got deleted?)\\n\\nfor gnd, title in zip(gnds, titles):\\n    print(\\n        f\\\"processed biographies: {j}/{number_biographies} (pkl stored: {k})| skipped: {len(missing_revision)}\\\",\\n        end=\\\"\\\\r\\\",\\n    )\\n    sleep(0.002)\\n    j += 1\\n    data_revisions_abs = os.path.join(\\n        path, data_revisions_rel, gnd + \\\"|\\\" + title + \\\".pkl\\\"\\n    )\\n    data_revisions_meta_abs = os.path.join(path, data_revisions_meta_rel, gnd + \\\".pkl\\\")\\n\\n    meta = {\\n        \\\"months\\\": get_months(),\\n        \\\"creator_user_id\\\": None,\\n        \\\"contributors\\\": {},\\n        \\\"created_month\\\": None,\\n        \\\"last_change_month\\\": None,\\n    }\\n    # contributors :: {user_id:{changes:<number>,user_names:[<user_names>]}\\n\\n    # relevant for reruns\\n    if os.path.exists(data_revisions_abs):\\n        continue\\n\\n    revisions = []\\n    # update params!\\n    params_updated = params\\n    params_updated[\\\"titles\\\"] = title.strip().replace(\\\" \\\", \\\"_\\\")\\n    params_updated.pop(\\\"rvcontinue\\\", None)  # reset params!\\n    try:\\n        for revision in get_revisions(params_updated):\\n            revisions.append(revision)\\n    except requests.exceptions.ConnectionError:\\n        # just rerun cell until dataset is complete\\n        connection_errors += 1\\n\\n    if len(revisions) == 0:\\n        continue\\n\\n    revisions_parsed = []\\n    # parse content\\n    for r in revisions:\\n        if \\\"*\\\" in r:\\n            r[\\\"text\\\"] = r.pop(\\\"*\\\")\\n            r.pop(\\\"anon\\\", None)\\n            r.pop(\\\"minor\\\", None)\\n            obj = r\\n            wikicode = r[\\\"text\\\"]\\n            try:\\n                wikicode_parsed = mwparserfromhell.parse(wikicode)\\n                obj[\\\"text\\\"] = wikicode_parsed.strip_code(normalize=True, collapse=True)\\n                obj[\\\"text\\\"] = (\\n                    obj[\\\"text\\\"]\\n                    .replace(\\\"\\\\r\\\\n\\\", \\\"\\\\n\\\")\\n                    .replace(\\\"\\\\r\\\", \\\"\\\\n\\\")\\n                    .replace(\\\"\\\\n\\\", \\\" \\\")\\n                )\\n                obj[\\\"text\\\"] = re.sub(\\n                    \\\" {2,}\\\", \\\" \\\", obj[\\\"text\\\"]\\n                )  # remove multiple whitespaces\\n            except mwparserfromhell.parser.ParserError:\\n                parser_errors += 1\\n            finally:\\n                revisions_parsed.append(obj)\\n\\n    # drop all but last version of every year (month not possible due to limited memory ressources)\\n    pattern_year_month = re.compile(r\\\"^\\\\d{4}-\\\\d{2}\\\")\\n    # pattern_year = re.compile(r\\\"^\\\\d{4}\\\")\\n    revisions_latest_by_month = []\\n    # revisions_latest_by_year = []\\n    occured_year_months = {}\\n    # occured_years = {}\\n\\n    first_revision = revisions_parsed[-1]\\n    # assure first revision -> article created with that version\\n    if first_revision[\\\"parentid\\\"] != 0:\\n        missing_first_revision += 1\\n        missing_revision[gnd] = revisions_parsed\\n        continue\\n\\n    meta[\\\"creator_user_id\\\"] = first_revision[\\\"userid\\\"]\\n    meta[\\\"created_month\\\"] = pattern_year_month.search(\\n        first_revision[\\\"timestamp\\\"]\\n    ).group(0)\\n    meta[\\\"last_change_month\\\"] = pattern_year_month.search(\\n        revisions_parsed[0][\\\"timestamp\\\"]\\n    ).group(0)\\n    try:\\n        for rev in revisions_parsed:\\n            timestamp = rev[\\\"timestamp\\\"]\\n\\n            year_month = pattern_year_month.search(timestamp).group(0)\\n\\n            meta[\\\"months\\\"][year_month] += 1\\n            if rev[\\\"userid\\\"] in meta[\\\"contributors\\\"]:\\n                meta[\\\"contributors\\\"][rev[\\\"userid\\\"]][\\\"changes\\\"] += 1\\n                if rev[\\\"user\\\"] not in meta[\\\"contributors\\\"][rev[\\\"userid\\\"]][\\\"user_names\\\"]:\\n                    meta[\\\"contributors\\\"][rev[\\\"userid\\\"]][\\\"user_names\\\"].append(\\n                        rev[\\\"user\\\"]\\n                    )\\n            else:\\n                meta[\\\"contributors\\\"][rev[\\\"userid\\\"]] = {\\n                    \\\"changes\\\": 1,\\n                    \\\"user_names\\\": [rev[\\\"user\\\"]],\\n                }\\n\\n            if year_month not in occured_year_months:\\n                occured_year_months[year_month] = None\\n                revisions_latest_by_month.append(rev)\\n\\n            \\\"\\\"\\\"\\n            year = pattern_year.search(timestamp).group(0)\\n            if year not in occured_years:\\n                occured_years[year] = None\\n                revisions_latest_by_year.append(rev)\\n            \\\"\\\"\\\"\\n    except KeyError as e:\\n        missing_revision[gnd] = revisions_parsed\\n        missing_userid_key += 1\\n        continue\\n\\n    assert len(revisions_parsed) == sum(meta[\\\"months\\\"].values())\\n    assert len(revisions_parsed) == sum(\\n        [v[\\\"changes\\\"] for k, v in meta[\\\"contributors\\\"].items()]\\n    )\\n\\n    # store df: <gnd>|<wikititle>.pkl\\n    # revisions_latest_by_year.reverse()\\n    revisions_latest_by_month.reverse()\\n    # df_biographie_revisions = pd.DataFrame(revisions_latest_by_year, dtype=\\\"string\\\")\\n    df_biographie_revisions = pd.DataFrame(revisions_latest_by_month, dtype=\\\"string\\\")\\n    df_biographie_revisions.to_pickle(data_revisions_abs)\\n    with open(data_revisions_meta_abs, \\\"wb\\\") as f:\\n        pickle.dump(meta, f, protocol=pickle.HIGHEST_PROTOCOL)\\n\\n    k += 1\\n    sleep(0.01)\\n\\nprint(\\\"\\\\n\\\")\\nprint(f\\\"{parser_errors=}\\\")\\nprint(f\\\"{connection_errors=}\\\")\\nprint(f\\\"{missing_first_revision=}\\\")\\nprint(f\\\"{missing_userid_key=}\\\")\";\n",
       "                var nbb_formatted_code = \"path = os.path.abspath(\\\"\\\")\\ndata_revisions_rel = \\\"data/revisions/\\\"\\ndata_revisions_meta_rel = \\\"data/revisions_meta/\\\"\\nj = 0\\nk = 0  # biographies with revsions\\nparser_errors = 0\\nconnection_errors = 0\\nmissing_revision = {}\\nmissing_userid_key = 0\\nmissing_first_revision = 0  # parentid != 0 (first revision got deleted?)\\n\\nfor gnd, title in zip(gnds, titles):\\n    print(\\n        f\\\"processed biographies: {j}/{number_biographies} (pkl stored: {k})| skipped: {len(missing_revision)}\\\",\\n        end=\\\"\\\\r\\\",\\n    )\\n    sleep(0.002)\\n    j += 1\\n    data_revisions_abs = os.path.join(\\n        path, data_revisions_rel, gnd + \\\"|\\\" + title + \\\".pkl\\\"\\n    )\\n    data_revisions_meta_abs = os.path.join(path, data_revisions_meta_rel, gnd + \\\".pkl\\\")\\n\\n    meta = {\\n        \\\"months\\\": get_months(),\\n        \\\"creator_user_id\\\": None,\\n        \\\"contributors\\\": {},\\n        \\\"created_month\\\": None,\\n        \\\"last_change_month\\\": None,\\n    }\\n    # contributors :: {user_id:{changes:<number>,user_names:[<user_names>]}\\n\\n    # relevant for reruns\\n    if os.path.exists(data_revisions_abs):\\n        continue\\n\\n    revisions = []\\n    # update params!\\n    params_updated = params\\n    params_updated[\\\"titles\\\"] = title.strip().replace(\\\" \\\", \\\"_\\\")\\n    params_updated.pop(\\\"rvcontinue\\\", None)  # reset params!\\n    try:\\n        for revision in get_revisions(params_updated):\\n            revisions.append(revision)\\n    except requests.exceptions.ConnectionError:\\n        # just rerun cell until dataset is complete\\n        connection_errors += 1\\n\\n    if len(revisions) == 0:\\n        continue\\n\\n    revisions_parsed = []\\n    # parse content\\n    for r in revisions:\\n        if \\\"*\\\" in r:\\n            r[\\\"text\\\"] = r.pop(\\\"*\\\")\\n            r.pop(\\\"anon\\\", None)\\n            r.pop(\\\"minor\\\", None)\\n            obj = r\\n            wikicode = r[\\\"text\\\"]\\n            try:\\n                wikicode_parsed = mwparserfromhell.parse(wikicode)\\n                obj[\\\"text\\\"] = wikicode_parsed.strip_code(normalize=True, collapse=True)\\n                obj[\\\"text\\\"] = (\\n                    obj[\\\"text\\\"]\\n                    .replace(\\\"\\\\r\\\\n\\\", \\\"\\\\n\\\")\\n                    .replace(\\\"\\\\r\\\", \\\"\\\\n\\\")\\n                    .replace(\\\"\\\\n\\\", \\\" \\\")\\n                )\\n                obj[\\\"text\\\"] = re.sub(\\n                    \\\" {2,}\\\", \\\" \\\", obj[\\\"text\\\"]\\n                )  # remove multiple whitespaces\\n            except mwparserfromhell.parser.ParserError:\\n                parser_errors += 1\\n            finally:\\n                revisions_parsed.append(obj)\\n\\n    # drop all but last version of every year (month not possible due to limited memory ressources)\\n    pattern_year_month = re.compile(r\\\"^\\\\d{4}-\\\\d{2}\\\")\\n    # pattern_year = re.compile(r\\\"^\\\\d{4}\\\")\\n    revisions_latest_by_month = []\\n    # revisions_latest_by_year = []\\n    occured_year_months = {}\\n    # occured_years = {}\\n\\n    first_revision = revisions_parsed[-1]\\n    # assure first revision -> article created with that version\\n    if first_revision[\\\"parentid\\\"] != 0:\\n        missing_first_revision += 1\\n        missing_revision[gnd] = revisions_parsed\\n        continue\\n\\n    meta[\\\"creator_user_id\\\"] = first_revision[\\\"userid\\\"]\\n    meta[\\\"created_month\\\"] = pattern_year_month.search(\\n        first_revision[\\\"timestamp\\\"]\\n    ).group(0)\\n    meta[\\\"last_change_month\\\"] = pattern_year_month.search(\\n        revisions_parsed[0][\\\"timestamp\\\"]\\n    ).group(0)\\n    try:\\n        for rev in revisions_parsed:\\n            timestamp = rev[\\\"timestamp\\\"]\\n\\n            year_month = pattern_year_month.search(timestamp).group(0)\\n\\n            meta[\\\"months\\\"][year_month] += 1\\n            if rev[\\\"userid\\\"] in meta[\\\"contributors\\\"]:\\n                meta[\\\"contributors\\\"][rev[\\\"userid\\\"]][\\\"changes\\\"] += 1\\n                if rev[\\\"user\\\"] not in meta[\\\"contributors\\\"][rev[\\\"userid\\\"]][\\\"user_names\\\"]:\\n                    meta[\\\"contributors\\\"][rev[\\\"userid\\\"]][\\\"user_names\\\"].append(\\n                        rev[\\\"user\\\"]\\n                    )\\n            else:\\n                meta[\\\"contributors\\\"][rev[\\\"userid\\\"]] = {\\n                    \\\"changes\\\": 1,\\n                    \\\"user_names\\\": [rev[\\\"user\\\"]],\\n                }\\n\\n            if year_month not in occured_year_months:\\n                occured_year_months[year_month] = None\\n                revisions_latest_by_month.append(rev)\\n\\n            \\\"\\\"\\\"\\n            year = pattern_year.search(timestamp).group(0)\\n            if year not in occured_years:\\n                occured_years[year] = None\\n                revisions_latest_by_year.append(rev)\\n            \\\"\\\"\\\"\\n    except KeyError as e:\\n        missing_revision[gnd] = revisions_parsed\\n        missing_userid_key += 1\\n        continue\\n\\n    assert len(revisions_parsed) == sum(meta[\\\"months\\\"].values())\\n    assert len(revisions_parsed) == sum(\\n        [v[\\\"changes\\\"] for k, v in meta[\\\"contributors\\\"].items()]\\n    )\\n\\n    # store df: <gnd>|<wikititle>.pkl\\n    # revisions_latest_by_year.reverse()\\n    revisions_latest_by_month.reverse()\\n    # df_biographie_revisions = pd.DataFrame(revisions_latest_by_year, dtype=\\\"string\\\")\\n    df_biographie_revisions = pd.DataFrame(revisions_latest_by_month, dtype=\\\"string\\\")\\n    df_biographie_revisions.to_pickle(data_revisions_abs)\\n    with open(data_revisions_meta_abs, \\\"wb\\\") as f:\\n        pickle.dump(meta, f, protocol=pickle.HIGHEST_PROTOCOL)\\n\\n    k += 1\\n    sleep(0.01)\\n\\nprint(\\\"\\\\n\\\")\\nprint(f\\\"{parser_errors=}\\\")\\nprint(f\\\"{connection_errors=}\\\")\\nprint(f\\\"{missing_first_revision=}\\\")\\nprint(f\\\"{missing_userid_key=}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = os.path.abspath(\"\")\n",
    "data_revisions_rel = \"data/revisions/\"\n",
    "data_revisions_meta_rel = \"data/revisions_meta/\"\n",
    "j = 0\n",
    "k = 0  # biographies with revsions\n",
    "parser_errors = 0\n",
    "connection_errors = 0\n",
    "missing_revision = {}\n",
    "missing_userid_key = 0\n",
    "missing_first_revision = 0  # parentid != 0 (first revision got deleted?)\n",
    "\n",
    "for gnd, title in zip(gnds, titles):\n",
    "    print(\n",
    "        f\"processed biographies: {j}/{number_biographies} (pkl stored: {k})| skipped: {len(missing_revision)}\",\n",
    "        end=\"\\r\",\n",
    "    )\n",
    "    sleep(0.002)\n",
    "    j += 1\n",
    "    data_revisions_abs = os.path.join(\n",
    "        path, data_revisions_rel, gnd + \"|\" + title + \".pkl\"\n",
    "    )\n",
    "    data_revisions_meta_abs = os.path.join(path, data_revisions_meta_rel, gnd + \".pkl\")\n",
    "\n",
    "    meta = {\n",
    "        \"months\": get_months(),\n",
    "        \"creator_user_id\": None,\n",
    "        \"contributors\": {},\n",
    "        \"created_month\": None,\n",
    "        \"last_change_month\": None,\n",
    "    }\n",
    "    # contributors :: {user_id:{changes:<number>,user_names:[<user_names>]}\n",
    "\n",
    "    # relevant for reruns\n",
    "    if os.path.exists(data_revisions_abs):\n",
    "        continue\n",
    "\n",
    "    revisions = []\n",
    "    # update params!\n",
    "    params_updated = params\n",
    "    params_updated[\"titles\"] = title.strip().replace(\" \", \"_\")\n",
    "    params_updated.pop(\"rvcontinue\", None)  # reset params!\n",
    "    try:\n",
    "        for revision in get_revisions(params_updated):\n",
    "            revisions.append(revision)\n",
    "    except requests.exceptions.ConnectionError:\n",
    "        # just rerun cell until dataset is complete\n",
    "        connection_errors += 1\n",
    "\n",
    "    if len(revisions) == 0:\n",
    "        continue\n",
    "\n",
    "    revisions_parsed = []\n",
    "    # parse content\n",
    "    for r in revisions:\n",
    "        if \"*\" in r:\n",
    "            r[\"text\"] = r.pop(\"*\")\n",
    "            r.pop(\"anon\", None)\n",
    "            r.pop(\"minor\", None)\n",
    "            obj = r\n",
    "            wikicode = r[\"text\"]\n",
    "            try:\n",
    "                wikicode_parsed = mwparserfromhell.parse(wikicode)\n",
    "                obj[\"text\"] = wikicode_parsed.strip_code(normalize=True, collapse=True)\n",
    "                obj[\"text\"] = (\n",
    "                    obj[\"text\"]\n",
    "                    .replace(\"\\r\\n\", \"\\n\")\n",
    "                    .replace(\"\\r\", \"\\n\")\n",
    "                    .replace(\"\\n\", \" \")\n",
    "                )\n",
    "                obj[\"text\"] = re.sub(\n",
    "                    \" {2,}\", \" \", obj[\"text\"]\n",
    "                )  # remove multiple whitespaces\n",
    "            except mwparserfromhell.parser.ParserError:\n",
    "                parser_errors += 1\n",
    "            finally:\n",
    "                revisions_parsed.append(obj)\n",
    "\n",
    "    # drop all but last version of every year (month not possible due to limited memory ressources)\n",
    "    pattern_year_month = re.compile(r\"^\\d{4}-\\d{2}\")\n",
    "    # pattern_year = re.compile(r\"^\\d{4}\")\n",
    "    revisions_latest_by_month = []\n",
    "    # revisions_latest_by_year = []\n",
    "    occured_year_months = {}\n",
    "    # occured_years = {}\n",
    "\n",
    "    first_revision = revisions_parsed[-1]\n",
    "    # assure first revision -> article created with that version\n",
    "    if first_revision[\"parentid\"] != 0:\n",
    "        missing_first_revision += 1\n",
    "        missing_revision[gnd] = revisions_parsed\n",
    "        continue\n",
    "\n",
    "    meta[\"creator_user_id\"] = first_revision[\"userid\"]\n",
    "    meta[\"created_month\"] = pattern_year_month.search(\n",
    "        first_revision[\"timestamp\"]\n",
    "    ).group(0)\n",
    "    meta[\"last_change_month\"] = pattern_year_month.search(\n",
    "        revisions_parsed[0][\"timestamp\"]\n",
    "    ).group(0)\n",
    "    try:\n",
    "        for rev in revisions_parsed:\n",
    "            timestamp = rev[\"timestamp\"]\n",
    "\n",
    "            year_month = pattern_year_month.search(timestamp).group(0)\n",
    "\n",
    "            meta[\"months\"][year_month] += 1\n",
    "            if rev[\"userid\"] in meta[\"contributors\"]:\n",
    "                meta[\"contributors\"][rev[\"userid\"]][\"changes\"] += 1\n",
    "                if rev[\"user\"] not in meta[\"contributors\"][rev[\"userid\"]][\"user_names\"]:\n",
    "                    meta[\"contributors\"][rev[\"userid\"]][\"user_names\"].append(\n",
    "                        rev[\"user\"]\n",
    "                    )\n",
    "            else:\n",
    "                meta[\"contributors\"][rev[\"userid\"]] = {\n",
    "                    \"changes\": 1,\n",
    "                    \"user_names\": [rev[\"user\"]],\n",
    "                }\n",
    "\n",
    "            if year_month not in occured_year_months:\n",
    "                occured_year_months[year_month] = None\n",
    "                revisions_latest_by_month.append(rev)\n",
    "\n",
    "            \"\"\"\n",
    "            year = pattern_year.search(timestamp).group(0)\n",
    "            if year not in occured_years:\n",
    "                occured_years[year] = None\n",
    "                revisions_latest_by_year.append(rev)\n",
    "            \"\"\"\n",
    "    except KeyError as e:\n",
    "        missing_revision[gnd] = revisions_parsed\n",
    "        missing_userid_key += 1\n",
    "        continue\n",
    "\n",
    "    assert len(revisions_parsed) == sum(meta[\"months\"].values())\n",
    "    assert len(revisions_parsed) == sum(\n",
    "        [v[\"changes\"] for k, v in meta[\"contributors\"].items()]\n",
    "    )\n",
    "\n",
    "    # store df: <gnd>|<wikititle>.pkl\n",
    "    # revisions_latest_by_year.reverse()\n",
    "    revisions_latest_by_month.reverse()\n",
    "    # df_biographie_revisions = pd.DataFrame(revisions_latest_by_year, dtype=\"string\")\n",
    "    df_biographie_revisions = pd.DataFrame(revisions_latest_by_month, dtype=\"string\")\n",
    "    df_biographie_revisions.to_pickle(data_revisions_abs)\n",
    "    with open(data_revisions_meta_abs, \"wb\") as f:\n",
    "        pickle.dump(meta, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    k += 1\n",
    "    sleep(0.01)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(f\"{parser_errors=}\")\n",
    "print(f\"{connection_errors=}\")\n",
    "print(f\"{missing_first_revision=}\")\n",
    "print(f\"{missing_userid_key=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 50;\n",
       "                var nbb_unformatted_code = \"# 20.484 (biographies that could be mapped)\\n# 20.457 (revisions+meta-data)\\n\\n# 27 missing (5 (missing first revision) + 22 (missing userid attribute))\";\n",
       "                var nbb_formatted_code = \"# 20.484 (biographies that could be mapped)\\n# 20.457 (revisions+meta-data)\\n\\n# 27 missing (5 (missing first revision) + 22 (missing userid attribute))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 20.484 (biographies that could be mapped)\n",
    "# 20.457 (revisions+meta-data)\n",
    "\n",
    "# 27 missing (5 (missing first revision) + 22 (missing userid attribute))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/andreas/thesis/ndb-wikipedia-reuse/data/revisions/189548401|Ernst Bücken.pkl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>revid</th>\n",
       "      <th>parentid</th>\n",
       "      <th>user</th>\n",
       "      <th>userid</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>contentformat</th>\n",
       "      <th>contentmodel</th>\n",
       "      <th>comment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105037428</td>\n",
       "      <td>105034856</td>\n",
       "      <td>Widerborst</td>\n",
       "      <td>1181049</td>\n",
       "      <td>2012-06-30T20:25:02Z</td>\n",
       "      <td>text/x-wiki</td>\n",
       "      <td>wikitext</td>\n",
       "      <td>/* Leben */</td>\n",
       "      <td>Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106351470</td>\n",
       "      <td>106351331</td>\n",
       "      <td>Gudrun Meyer</td>\n",
       "      <td>298151</td>\n",
       "      <td>2012-08-03T21:17:15Z</td>\n",
       "      <td>text/x-wiki</td>\n",
       "      <td>wikitext</td>\n",
       "      <td>/* Leben */ fehlendes Wort ergänzt</td>\n",
       "      <td>Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110007150</td>\n",
       "      <td>106351470</td>\n",
       "      <td>Adippold</td>\n",
       "      <td>1014143</td>\n",
       "      <td>2012-11-01T23:44:57Z</td>\n",
       "      <td>text/x-wiki</td>\n",
       "      <td>wikitext</td>\n",
       "      <td>/* Leben */ typo</td>\n",
       "      <td>Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>113244073</td>\n",
       "      <td>110007150</td>\n",
       "      <td>Fomafix</td>\n",
       "      <td>154724</td>\n",
       "      <td>2013-01-21T15:47:21Z</td>\n",
       "      <td>text/x-wiki</td>\n",
       "      <td>wikitext</td>\n",
       "      <td>[[Halbgeviertstrich]] ([[–]]) statt [[Minuszei...</td>\n",
       "      <td>Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122909321</td>\n",
       "      <td>113244073</td>\n",
       "      <td>Nicht aus dem Sinn</td>\n",
       "      <td>1308505</td>\n",
       "      <td>2013-09-26T20:33:21Z</td>\n",
       "      <td>text/x-wiki</td>\n",
       "      <td>wikitext</td>\n",
       "      <td></td>\n",
       "      <td>Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>126344918</td>\n",
       "      <td>122909321</td>\n",
       "      <td>Majo statt Senf</td>\n",
       "      <td>1722994</td>\n",
       "      <td>2014-01-11T05:41:30Z</td>\n",
       "      <td>text/x-wiki</td>\n",
       "      <td>wikitext</td>\n",
       "      <td>[[WP:HC|HC]]: +[[Kategorie:Hochschullehrer (Hf...</td>\n",
       "      <td>Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>151198992</td>\n",
       "      <td>126344918</td>\n",
       "      <td>Jaellee</td>\n",
       "      <td>214011</td>\n",
       "      <td>2016-02-07T16:55:02Z</td>\n",
       "      <td>text/x-wiki</td>\n",
       "      <td>wikitext</td>\n",
       "      <td>Typographische Anführungszeichen korrigiert | ...</td>\n",
       "      <td>Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>153151500</td>\n",
       "      <td>151198992</td>\n",
       "      <td>JohnSpecialK</td>\n",
       "      <td>1211895</td>\n",
       "      <td>2016-04-04T08:17:42Z</td>\n",
       "      <td>text/x-wiki</td>\n",
       "      <td>wikitext</td>\n",
       "      <td>/* Leben */</td>\n",
       "      <td>Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>161343017</td>\n",
       "      <td>153151500</td>\n",
       "      <td>TaxonBot</td>\n",
       "      <td>1824919</td>\n",
       "      <td>2017-01-06T03:39:57Z</td>\n",
       "      <td>text/x-wiki</td>\n",
       "      <td>wikitext</td>\n",
       "      <td>Bot: Korrektur Halbgeviertstrich</td>\n",
       "      <td>Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>167739363</td>\n",
       "      <td>161343017</td>\n",
       "      <td>Reiner Stoppok</td>\n",
       "      <td>230318</td>\n",
       "      <td>2017-07-31T03:03:12Z</td>\n",
       "      <td>text/x-wiki</td>\n",
       "      <td>wikitext</td>\n",
       "      <td>/* Werke (Auswahl) */</td>\n",
       "      <td>Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>168088694</td>\n",
       "      <td>168069002</td>\n",
       "      <td>Khatschaturjan</td>\n",
       "      <td>2248609</td>\n",
       "      <td>2017-08-12T08:53:04Z</td>\n",
       "      <td>text/x-wiki</td>\n",
       "      <td>wikitext</td>\n",
       "      <td>/* Leben */</td>\n",
       "      <td>Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>171445298</td>\n",
       "      <td>168088694</td>\n",
       "      <td>Budelmütze</td>\n",
       "      <td>520030</td>\n",
       "      <td>2017-11-27T16:42:10Z</td>\n",
       "      <td>text/x-wiki</td>\n",
       "      <td>wikitext</td>\n",
       "      <td></td>\n",
       "      <td>mini||Ernst Bücken vor 1930 Ernst Bücken (* 2....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>172206529</td>\n",
       "      <td>171445298</td>\n",
       "      <td>80.143.215.74</td>\n",
       "      <td>0</td>\n",
       "      <td>2017-12-22T19:01:02Z</td>\n",
       "      <td>text/x-wiki</td>\n",
       "      <td>wikitext</td>\n",
       "      <td></td>\n",
       "      <td>mini|Ernst Bücken vor 1930 Ernst Bücken (* 2. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>175181697</td>\n",
       "      <td>172206529</td>\n",
       "      <td>CommonsDelinker</td>\n",
       "      <td>280975</td>\n",
       "      <td>2018-03-19T17:52:22Z</td>\n",
       "      <td>text/x-wiki</td>\n",
       "      <td>wikitext</td>\n",
       "      <td>[[:c:File:Ernst_Bücken_vor_1930.jpg|Ernst_Bück...</td>\n",
       "      <td>Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>181916586</td>\n",
       "      <td>175181697</td>\n",
       "      <td>Aka</td>\n",
       "      <td>568</td>\n",
       "      <td>2018-10-18T17:27:54Z</td>\n",
       "      <td>text/x-wiki</td>\n",
       "      <td>wikitext</td>\n",
       "      <td>/* Werke (Auswahl) */ Halbgeviertstrich</td>\n",
       "      <td>Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>183408811</td>\n",
       "      <td>183404348</td>\n",
       "      <td>Aka</td>\n",
       "      <td>568</td>\n",
       "      <td>2018-12-04T20:16:02Z</td>\n",
       "      <td>text/x-wiki</td>\n",
       "      <td>wikitext</td>\n",
       "      <td>/* Werke (Auswahl) */ Halbgeviertstrich</td>\n",
       "      <td>Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>187826116</td>\n",
       "      <td>187394224</td>\n",
       "      <td>Wheeke</td>\n",
       "      <td>1347043</td>\n",
       "      <td>2019-04-23T08:42:08Z</td>\n",
       "      <td>text/x-wiki</td>\n",
       "      <td>wikitext</td>\n",
       "      <td>/* Einleitung */</td>\n",
       "      <td>Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>208231863</td>\n",
       "      <td>187826116</td>\n",
       "      <td>Fisches Nachtgesang</td>\n",
       "      <td>1791236</td>\n",
       "      <td>2021-01-30T08:42:11Z</td>\n",
       "      <td>text/x-wiki</td>\n",
       "      <td>wikitext</td>\n",
       "      <td>/* Leben */</td>\n",
       "      <td>Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>209425436</td>\n",
       "      <td>208231863</td>\n",
       "      <td>Lubitsch2</td>\n",
       "      <td>3619572</td>\n",
       "      <td>2021-03-04T03:08:51Z</td>\n",
       "      <td>text/x-wiki</td>\n",
       "      <td>wikitext</td>\n",
       "      <td></td>\n",
       "      <td>Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>214804781</td>\n",
       "      <td>214790191</td>\n",
       "      <td>Aka</td>\n",
       "      <td>568</td>\n",
       "      <td>2021-08-16T10:34:45Z</td>\n",
       "      <td>text/x-wiki</td>\n",
       "      <td>wikitext</td>\n",
       "      <td>/* Literatur */ Halbgeviertstrich, Kleinkram</td>\n",
       "      <td>Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        revid   parentid                 user   userid             timestamp  \\\n",
       "0   105037428  105034856           Widerborst  1181049  2012-06-30T20:25:02Z   \n",
       "1   106351470  106351331         Gudrun Meyer   298151  2012-08-03T21:17:15Z   \n",
       "2   110007150  106351470             Adippold  1014143  2012-11-01T23:44:57Z   \n",
       "3   113244073  110007150              Fomafix   154724  2013-01-21T15:47:21Z   \n",
       "4   122909321  113244073   Nicht aus dem Sinn  1308505  2013-09-26T20:33:21Z   \n",
       "5   126344918  122909321      Majo statt Senf  1722994  2014-01-11T05:41:30Z   \n",
       "6   151198992  126344918              Jaellee   214011  2016-02-07T16:55:02Z   \n",
       "7   153151500  151198992         JohnSpecialK  1211895  2016-04-04T08:17:42Z   \n",
       "8   161343017  153151500             TaxonBot  1824919  2017-01-06T03:39:57Z   \n",
       "9   167739363  161343017       Reiner Stoppok   230318  2017-07-31T03:03:12Z   \n",
       "10  168088694  168069002       Khatschaturjan  2248609  2017-08-12T08:53:04Z   \n",
       "11  171445298  168088694           Budelmütze   520030  2017-11-27T16:42:10Z   \n",
       "12  172206529  171445298        80.143.215.74        0  2017-12-22T19:01:02Z   \n",
       "13  175181697  172206529      CommonsDelinker   280975  2018-03-19T17:52:22Z   \n",
       "14  181916586  175181697                  Aka      568  2018-10-18T17:27:54Z   \n",
       "15  183408811  183404348                  Aka      568  2018-12-04T20:16:02Z   \n",
       "16  187826116  187394224               Wheeke  1347043  2019-04-23T08:42:08Z   \n",
       "17  208231863  187826116  Fisches Nachtgesang  1791236  2021-01-30T08:42:11Z   \n",
       "18  209425436  208231863            Lubitsch2  3619572  2021-03-04T03:08:51Z   \n",
       "19  214804781  214790191                  Aka      568  2021-08-16T10:34:45Z   \n",
       "\n",
       "   contentformat contentmodel  \\\n",
       "0    text/x-wiki     wikitext   \n",
       "1    text/x-wiki     wikitext   \n",
       "2    text/x-wiki     wikitext   \n",
       "3    text/x-wiki     wikitext   \n",
       "4    text/x-wiki     wikitext   \n",
       "5    text/x-wiki     wikitext   \n",
       "6    text/x-wiki     wikitext   \n",
       "7    text/x-wiki     wikitext   \n",
       "8    text/x-wiki     wikitext   \n",
       "9    text/x-wiki     wikitext   \n",
       "10   text/x-wiki     wikitext   \n",
       "11   text/x-wiki     wikitext   \n",
       "12   text/x-wiki     wikitext   \n",
       "13   text/x-wiki     wikitext   \n",
       "14   text/x-wiki     wikitext   \n",
       "15   text/x-wiki     wikitext   \n",
       "16   text/x-wiki     wikitext   \n",
       "17   text/x-wiki     wikitext   \n",
       "18   text/x-wiki     wikitext   \n",
       "19   text/x-wiki     wikitext   \n",
       "\n",
       "                                              comment  \\\n",
       "0                                         /* Leben */   \n",
       "1                  /* Leben */ fehlendes Wort ergänzt   \n",
       "2                                    /* Leben */ typo   \n",
       "3   [[Halbgeviertstrich]] ([[–]]) statt [[Minuszei...   \n",
       "4                                                       \n",
       "5   [[WP:HC|HC]]: +[[Kategorie:Hochschullehrer (Hf...   \n",
       "6   Typographische Anführungszeichen korrigiert | ...   \n",
       "7                                         /* Leben */   \n",
       "8                    Bot: Korrektur Halbgeviertstrich   \n",
       "9                               /* Werke (Auswahl) */   \n",
       "10                                        /* Leben */   \n",
       "11                                                      \n",
       "12                                                      \n",
       "13  [[:c:File:Ernst_Bücken_vor_1930.jpg|Ernst_Bück...   \n",
       "14            /* Werke (Auswahl) */ Halbgeviertstrich   \n",
       "15            /* Werke (Auswahl) */ Halbgeviertstrich   \n",
       "16                                   /* Einleitung */   \n",
       "17                                        /* Leben */   \n",
       "18                                                      \n",
       "19       /* Literatur */ Halbgeviertstrich, Kleinkram   \n",
       "\n",
       "                                                 text  \n",
       "0   Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...  \n",
       "1   Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...  \n",
       "2   Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...  \n",
       "3   Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...  \n",
       "4   Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...  \n",
       "5   Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...  \n",
       "6   Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...  \n",
       "7   Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...  \n",
       "8   Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...  \n",
       "9   Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...  \n",
       "10  Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...  \n",
       "11  mini||Ernst Bücken vor 1930 Ernst Bücken (* 2....  \n",
       "12  mini|Ernst Bücken vor 1930 Ernst Bücken (* 2. ...  \n",
       "13  Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...  \n",
       "14  Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...  \n",
       "15  Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...  \n",
       "16  Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...  \n",
       "17  Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...  \n",
       "18  Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...  \n",
       "19  Ernst Bücken (* 2. Juni 1884 in Aachen; † 28. ...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"path = os.path.abspath(\\\"\\\")\\ndata_df_rel = \\\"data/revisions/\\\"\\ndata_df_ndb_abs = os.path.join(path, data_df_rel, \\\"189548401|Ernst B\\u00fccken.pkl\\\")\\nprint(data_df_ndb_abs)\\ncorpus = pd.read_pickle(data_df_ndb_abs)\\ncorpus\";\n",
       "                var nbb_formatted_code = \"path = os.path.abspath(\\\"\\\")\\ndata_df_rel = \\\"data/revisions/\\\"\\ndata_df_ndb_abs = os.path.join(path, data_df_rel, \\\"189548401|Ernst B\\u00fccken.pkl\\\")\\nprint(data_df_ndb_abs)\\ncorpus = pd.read_pickle(data_df_ndb_abs)\\ncorpus\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = os.path.abspath(\"\")\n",
    "data_df_rel = \"data/revisions/\"\n",
    "data_df_ndb_abs = os.path.join(path, data_df_rel, \"189548401|Ernst Bücken.pkl\")\n",
    "print(data_df_ndb_abs)\n",
    "corpus = pd.read_pickle(data_df_ndb_abs)\n",
    "corpus"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python38564bit13719079319b43f28007a75a272eccd3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
